{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/eym16/anaconda3/lib/python3.6/site-packages')\n",
    "\n",
    "import numpy as np\n",
    "import bisect\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras.backend as K\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import keras.regularizers\n",
    "\n",
    "import keras_resnet.blocks\n",
    "import keras_resnet.layers\n",
    "import keras_resnet.models\n",
    "\n",
    "import numpy as np\n",
    "import bisect\n",
    "from __future__ import print_function\n",
    "\n",
    "keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 15, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#frames generator class\n",
    "class Frame_generator(object):\n",
    "\n",
    "    def __init__(self, dim, train_samples=4):\n",
    "#         self.array = array\n",
    "        self.dim = dim\n",
    "        self.train_samples = train_samples\n",
    "        self.zeros = np.zeros((dim, dim))\n",
    "#         self.itemindex = self.itemindex_fun\n",
    "#         self.indices = self.datasets_indices\n",
    "#         self.frame = self.frame(x=array)\n",
    "        \n",
    "#     def itemindex_fun(self,value):\n",
    "#         itemindex = np.where(self.array==value)\n",
    "#         return itemindex\n",
    "    \n",
    "#     def datasets_indices(self, train_samples):\n",
    "#         indices = np.arange(len(self.itemindex(1)[0]))\n",
    "#         one_indices =  random.sample(list(indices), train_samples)\n",
    "#         return(one_indices)\n",
    "\n",
    "    #using self.definitions for the functions didn't work out\n",
    "    #forward part doesn't work\n",
    "    def frame(self, loc1, loc2):\n",
    "        res = np.copy(self.zeros)\n",
    "        for i,j in zip(loc1,loc2):\n",
    "#             print('i:', i)\n",
    "#             print('j:', j)\n",
    "            res[i][j]+=1\n",
    "            if i==0 and j==0:\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif i==0 and j==self.dim-1:\n",
    "                res[i][j-1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "            elif i==self.dim-1 and j==0:\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j+1]+=1\n",
    "            elif i==self.dim-1 and j==self.dim-1:\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i][j-1]+=1\n",
    "            elif i==0:\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif i==self.dim-1:\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "            elif j==0:\n",
    "                res[i-1][j]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif j==self.dim-1:\n",
    "                res[i-1][j]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i][j-1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "            else:\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "\n",
    "        return(res)\n",
    "    \n",
    "    #produce dataset\n",
    "    def frames(self, n_frames, loc1, loc2):\n",
    "        frames = np.empty((n_frames, self.dim, self.dim))\n",
    "        for i in range(n_frames):\n",
    "            loc1_tmp = loc1[loc1[:,i].nonzero()[0],i]\n",
    "            loc2_tmp = loc2[loc2[:,i].nonzero()[0],i]\n",
    "            intervals = np.arange(0,1,1/self.dim)\n",
    "            loc1_index = []\n",
    "            loc2_index = []\n",
    "#             print(loc1_tmp.shape)\n",
    "            for n in range(loc1_tmp.shape[0]):\n",
    "#                 print(loc1_tmp)\n",
    "                loc1_index.append(bisect.bisect_left(intervals, loc1_tmp[n])-1)\n",
    "                loc2_index.append(bisect.bisect_left(intervals, loc2_tmp[n])-1)\n",
    "            frames[i][:][:]=self.frame(loc1_index, loc2_index)\n",
    "        return frames\n",
    "\n",
    "# final image generator\n",
    "def final_image(dim, n_frames):\n",
    "    n = np.random.poisson(lam=10, size=1)\n",
    "    loc_mat = np.random.rand(n[0],2)\n",
    "    intervals = np.arange(0,1,1/dim)\n",
    "    loc1 = []\n",
    "    loc2 = []\n",
    "    for n in range(loc_mat.shape[0]):\n",
    "        loc1.append(bisect.bisect_left(intervals, loc_mat[n,0])-1)\n",
    "        loc2.append(bisect.bisect_left(intervals, loc_mat[n,1])-1)\n",
    "    x = np.zeros((dim,dim))\n",
    "    for i,j in zip(loc1,loc2):\n",
    "        x[i][j] += 1\n",
    "    #generate location matrices\n",
    "#     print(loc_mat[:,0].shape)\n",
    "    binom = np.random.binomial(n=1,p=min(1,4/loc_mat.shape[0]),size=(loc_mat.shape[0],n_frames))\n",
    "#     print(binom.shape)\n",
    "    loc1 = np.multiply(np.reshape(loc_mat[:,0],(loc_mat.shape[0],-1)),binom)\n",
    "    loc2 = np.multiply(np.reshape(loc_mat[:,1],(loc_mat.shape[0],-1)),binom)\n",
    "    loc1 = loc1[loc1[:,:].nonzero()[0],:]\n",
    "    loc2 = loc2[loc2[:,:].nonzero()[0],:]\n",
    "    return(x, loc1, loc2)\n",
    "\n",
    "\n",
    "# images generator function\n",
    "def frames_data_fun(n_images, n_frames, dim):\n",
    "    labels = np.zeros((n_images, 2, dim, dim))\n",
    "    data = np.empty((n_images, n_frames, dim, dim))\n",
    "    for n in range(n_images):\n",
    "        x, loc1, loc2 = final_image(dim, n_frames)\n",
    "        tmp = Frame_generator(dim)\n",
    "        frames = tmp.frames(n_frames=n_frames, loc1=loc1, loc2=loc2)\n",
    "        labels[n][1][:][:]=x\n",
    "        m = (x!=0)\n",
    "        labels[n][0][:][:]=1*m\n",
    "        data[n][:][:][:]=frames\n",
    "    return(labels, data)\n",
    "\n",
    "# call images generator function\n",
    "# 1000 images, 10000 frames, 100X100 dimension\n",
    "n_images = 10\n",
    "n_frames = 15\n",
    "dim = 10\n",
    "res = frames_data_fun(n_images=n_images, n_frames=n_frames, dim=dim)\n",
    "labels = res[0]\n",
    "data = res[1]\n",
    "\n",
    "print(data.shape)\n",
    "# print('data frame:', data[2,3,:,:])\n",
    "# print('lable:', labels[2,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 15, 10, 10)\n",
      "(2, 15, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data_samples = len(data)\n",
    "train_samples = round(0.8*data_samples)\n",
    "\n",
    "# Data loader\n",
    "def datasets_indices(data_samples, train_samples):    \n",
    "    indices = np.arange(data_samples)\n",
    "    #print(indices)\n",
    "    train_indices =  random.sample(list(indices), train_samples)\n",
    "    #print(train_indices)\n",
    "    test_indices = list(set(list(indices))-set(train_indices))\n",
    "    #print(test_indices)\n",
    "    return(train_indices, test_indices)\n",
    "\n",
    "indices = datasets_indices(data_samples, train_samples)\n",
    "train_loader = data[indices[0],:,:,:]\n",
    "train_labels = labels[indices[0],:,:]\n",
    "test_loader = data[indices[1],:,:,:]\n",
    "test_labels = labels[indices[1],:,:]\n",
    "\n",
    "print(train_loader.shape)\n",
    "print(test_loader.shape)\n",
    "\n",
    "input_dim = train_loader.shape[2]\n",
    "n_frames = train_loader.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 15, 10, 10, 32)\n",
      "bn1 (?, 15, 10, 10, 16)\n",
      "ac1 (?, 15, 10, 10, 16)\n",
      "conv1 (?, 15, 10, 10, 32)\n",
      "bn2 (?, 15, 10, 10, 32)\n",
      "ac2 (?, 15, 10, 10, 32)\n",
      "conv2 (?, 15, 10, 10, 32)\n",
      "skip shape (?, 15, 10, 10, 32)\n",
      "conv shape (?, 15, 10, 10, 32)\n",
      "prev shape (?, 15, 10, 10, 16)\n",
      "Residual block mapping 16 channels to 32 channels built\n",
      "(?, 15, 10, 10, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/2018-02-19/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/eym16/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1 (?, 15, 10, 10, 32)\n",
      "ac1 (?, 15, 10, 10, 32)\n",
      "conv1 (?, 15, 10, 10, 64)\n",
      "bn2 (?, 15, 10, 10, 64)\n",
      "ac2 (?, 15, 10, 10, 64)\n",
      "conv2 (?, 15, 10, 10, 64)\n",
      "skip shape (?, 15, 10, 10, 64)\n",
      "conv shape (?, 15, 10, 10, 64)\n",
      "prev shape (?, 15, 10, 10, 32)\n",
      "Residual block mapping 32 channels to 64 channels built\n",
      "bn1 (?, 15, 10, 10, 64)\n",
      "ac1 (?, 15, 10, 10, 64)\n",
      "conv1 (?, 15, 10, 10, 64)\n",
      "bn2 (?, 15, 10, 10, 64)\n",
      "ac2 (?, 15, 10, 10, 64)\n",
      "conv2 (?, 15, 10, 10, 64)\n",
      "skip shape (?, 15, 10, 10, 64)\n",
      "conv shape (?, 15, 10, 10, 64)\n",
      "prev shape (?, 15, 10, 10, 64)\n",
      "Residual block mapping 64 channels to 64 channels built\n",
      "r3 shape (?, 15, 10, 10, 64)\n",
      "r4 shape (?, 15, 10, 10, 64)\n",
      "out shape (?, 10, 10, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/2018-02-19/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:81: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '_keras_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-71d93b5f269f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;31m#     model.compile(optimizer=Nadam(lr=1e-5), loss='mean_squared_error')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m   1732\u001b[0m         \u001b[0mnodes_in_progress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1734\u001b[0;31m             \u001b[0mbuild_map_of_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_in_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_in_decreasing_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mbuild_map_of_graph\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                 \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 build_map_of_graph(x, finished_nodes, nodes_in_progress,\n\u001b[0;32m-> 1724\u001b[0;31m                                    layer, node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mbuild_map_of_graph\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \"\"\"\n\u001b[1;32m   1694\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnode_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '_keras_history'"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam\n",
    "from keras.layers import BatchNormalization, Convolution2D, Input, merge\n",
    "from keras.layers.core import Activation, Layer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pydot\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    "Keras Customizable Residual Unit\n",
    "This is a simplified implementation of the basic (no bottlenecks) full pre-activation residual unit from He, K., Zhang, X., Ren, S., Sun, J., \"Identity Mappings in Deep Residual Networks\" (http://arxiv.org/abs/1603.05027v2).\n",
    "'''\n",
    "#hyper parameters\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "def conv_block(feat_maps_out, prev):\n",
    "    prev = keras.layers.TimeDistributed(BatchNormalization(axis=1))(prev) # Specifying the axis and mode allows for later merging\n",
    "    print('bn1', prev.shape)\n",
    "    prev = keras.layers.TimeDistributed(Activation('relu'))(prev)\n",
    "    print('ac1', prev.shape)\n",
    "    prev = keras.layers.TimeDistributed(Convolution2D(feat_maps_out, kernel_size=3, strides=1, padding='same'))(prev)\n",
    "    print('conv1', prev.shape)\n",
    "    prev = keras.layers.TimeDistributed(BatchNormalization(axis=1))(prev) # Specifying the axis and mode allows for later merging\n",
    "    print('bn2', prev.shape)\n",
    "    prev = keras.layers.TimeDistributed(Activation('relu'))(prev)\n",
    "    print('ac2', prev.shape)\n",
    "    prev = keras.layers.TimeDistributed(Convolution2D(feat_maps_out, 3, strides=1, padding='same'))(prev)\n",
    "    print('conv2', prev.shape)\n",
    "    return prev\n",
    "\n",
    "\n",
    "def skip_block(feat_maps_in, feat_maps_out, prev):\n",
    "    if feat_maps_in != feat_maps_out:\n",
    "        # This adds in a 1x1 convolution on shortcuts that map between an uneven amount of channels\n",
    "        prev = keras.layers.TimeDistributed(Convolution2D(feat_maps_out, 1, strides=1, padding='same'))(prev)\n",
    "        print(prev.shape)\n",
    "    return prev \n",
    "\n",
    "\n",
    "def Residual(feat_maps_in, feat_maps_out, prev_layer):\n",
    "    '''\n",
    "    A customizable residual unit with convolutional and shortcut blocks\n",
    "    Args:\n",
    "      feat_maps_in: number of channels/filters coming in, from input or previous layer\n",
    "      feat_maps_out: how many output channels/filters this block will produce\n",
    "      prev_layer: the previous layer\n",
    "    '''\n",
    "\n",
    "    skip = skip_block(feat_maps_in, feat_maps_out, prev_layer)\n",
    "    conv = conv_block(feat_maps_out, prev_layer)\n",
    "    \n",
    "    print('skip shape', skip.shape)\n",
    "    print('conv shape', conv.shape)\n",
    "    print('prev shape', prev_layer.shape)\n",
    "\n",
    "    print('Residual block mapping '+str(feat_maps_in)+' channels to '+str(feat_maps_out)+' channels built')\n",
    "    return merge([skip, conv], mode='sum') # the residual connection\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # NOTE: Toy example shows structure\n",
    "    img_rows = dim  \n",
    "    img_cols = dim \n",
    "\n",
    "    inp = Input((n_frames, img_rows, img_cols, 1))\n",
    "    cnv1 = keras.layers.TimeDistributed(Convolution2D(16, kernel_size=3, strides=1, activation='relu', input_shape=(n_frames, img_rows, img_cols, 1), padding='same'))(inp)\n",
    "    r1 = Residual(16, 32, cnv1)\n",
    "    # An example residual unit coming after a convolutional layer. NOTE: the above residual takes the 64 output channels\n",
    "    # from the Convolutional2D layer as the first argument to the Residual function\n",
    "    r2 = Residual(32, 64, r1)\n",
    "    r3 = Residual(64, 64, r2)\n",
    "    print('r3 shape', r3.shape)\n",
    "#     r4 = keras.backend.reshape(r3, (-1,10,10,r3.shape[1]*r3.shape[4]))\n",
    "    r4 = (lambda x: keras.backend.reshape(x, (-1,10,10,x.shape[1]*x.shape[4])))(r3)\n",
    "    print('r4 shape', r3.shape)\n",
    "    out = keras.layers.Convolution2D(2, 1, strides=1, activation='sigmoid', padding='same')(r4)\n",
    "    print('out shape', out.shape)\n",
    "\n",
    "    model = Model(input=inp, output=out)\n",
    "#     model.compile(optimizer=Nadam(lr=1e-5), loss='mean_squared_error')\n",
    "\n",
    "#     plot_model(model, to_file='./toy_model.png', show_shapes=True)\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "####define a loss function\n",
    "\n",
    "def customloss(y_true, y_pred):\n",
    "    loss_layer0 = -(y_true[:,0,:,:]*K.log(y_pred[:,0,:,:])*10+(1-y_true[:,0,:,:])*K.log(1-y_pred[:,0,:,:]))\n",
    "#         print(loss_layer0)\n",
    "    loss_layer0 = K.sum(loss_layer0)\n",
    "    loss_layer1 = 0\n",
    "    print('y_pred shape', y_pred.shape)\n",
    "    loss_layer1 = K.abs(y_true[:,1,:,:]-y_pred[:,1,:,:])/K.cast(K.pow(y_pred.shape[2],2), 'float32')*(y_true[:,0,:,:]==1)\n",
    "    totloss = loss_layer0+loss_layer1\n",
    "    return totloss\n",
    "    \n",
    "####\n",
    "\n",
    "####compile the model\n",
    "\n",
    "model.compile(loss=customloss,\n",
    "              optimizer='adam'\n",
    "             )\n",
    "\n",
    "####\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Train...')\n",
    "    \n",
    "    print('shape:', (np.expand_dims(train_loader,4)).shape)\n",
    "    \n",
    "    model.fit(np.expand_dims(train_loader,4), np.expand_dims(train_labels,4),\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs)\n",
    "\n",
    "    ## train accuracy\n",
    "    print('#########')\n",
    "    print('train results')\n",
    "    train_pred = model.predict(np.expand_dims(train_loader,4))\n",
    "    predicted = train_pred.round()\n",
    "    labels = train_labels\n",
    "    print('labels shape', labels.shape)\n",
    "    total = labels.shape[0]*labels.shape[2]*labels.shape[3]\n",
    "    m = (labels[:,0,:,:]>0)*(predicted[:,0,:,:] == labels[:,0,:,:])\n",
    "    print('predicted', predicted[:,:,:,:].shape)\n",
    "    print('labels', labels[:,0,:,:].shape)\n",
    "    correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()-(m*(predicted[:,1,:,:] != labels[:,1,:,:])).sum().item()\n",
    "    semi_correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()\n",
    "    total_ones =  (labels[:,0,:,:]==1).sum().item()\n",
    "    total_zeros = (labels[:,0,:,:]==0).sum().item()\n",
    "    correct_ones = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==1)).sum().item()\n",
    "    correct_zeros = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==0)).sum().item()\n",
    "    print(correct_ones, total_ones, correct_zeros, total_zeros)\n",
    "    print('accuracy:', correct/total*100, '%')\n",
    "    print('semi_correct:', semi_correct/total*100, '%')\n",
    "    print('correct ones:', correct_ones/total_ones*100, '%')\n",
    "    print('correct zeros:', correct_zeros/total_zeros*100, '%')\n",
    "    \n",
    "## test accuracy\n",
    "    print('#########')\n",
    "    print('test results')\n",
    "    test_pred = model.predict(np.expand_dims(test_loader,4))\n",
    "    predicted = test_pred.round()\n",
    "    labels = test_labels\n",
    "    total = labels.shape[0]*labels.shape[2]*labels.shape[3]\n",
    "    print('label shape', labels.shape)\n",
    "    print('total', total)\n",
    "    m = (labels[:,0,:,:]>0)*(predicted[:,0,:,:] == labels[:,0,:,:])\n",
    "    correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()-(m*(predicted[:,1,:,:] != labels[:,1,:,:])).sum().item()\n",
    "    semi_correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()\n",
    "    print('correct', correct)\n",
    "    print('semi correct', semi_correct)\n",
    "    total_ones =  (labels[:,0,:,:]==1).sum().item()\n",
    "    total_zeros = (labels[:,0,:,:]==0).sum().item()\n",
    "    correct_ones = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==1)).sum().item()\n",
    "    correct_zeros = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==0)).sum().item()\n",
    "    print(correct_ones, total_ones, correct_zeros, total_zeros)\n",
    "    print('accuracy:', correct/total*100, '%')\n",
    "    print('semi_correct:', semi_correct/total*100, '%')\n",
    "    print('correct ones:', correct_ones/total_ones*100, '%')\n",
    "    print('correct zeros:', correct_zeros/total_zeros*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([1, 3])\n",
    "print((a==b).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
