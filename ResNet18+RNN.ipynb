{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 18 modified with generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/eym16/anaconda3/lib/python3.6/site-packages')\n",
    "\n",
    "import numpy as np\n",
    "import bisect\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling2D, Conv2D\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.datasets import imdb\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers import InputLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 20, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#frames generator class\n",
    "class Frame_generator(object):\n",
    "\n",
    "    def __init__(self, dim, train_samples=4):\n",
    "#         self.array = array\n",
    "        self.dim = dim\n",
    "        self.train_samples = train_samples\n",
    "        self.zeros = np.zeros((dim, dim))\n",
    "#         self.itemindex = self.itemindex_fun\n",
    "#         self.indices = self.datasets_indices\n",
    "#         self.frame = self.frame(x=array)\n",
    "        \n",
    "#     def itemindex_fun(self,value):\n",
    "#         itemindex = np.where(self.array==value)\n",
    "#         return itemindex\n",
    "    \n",
    "#     def datasets_indices(self, train_samples):\n",
    "#         indices = np.arange(len(self.itemindex(1)[0]))\n",
    "#         one_indices =  random.sample(list(indices), train_samples)\n",
    "#         return(one_indices)\n",
    "\n",
    "    #using self.definitions for the functions didn't work out\n",
    "    #forward part doesn't work\n",
    "    def frame(self, loc1, loc2):\n",
    "        res = np.copy(self.zeros)\n",
    "        for i,j in zip(loc1,loc2):\n",
    "#             print('i:', i)\n",
    "#             print('j:', j)\n",
    "            res[i][j]+=1\n",
    "            if i==0 and j==0:\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif i==0 and j==self.dim-1:\n",
    "                res[i][j-1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "            elif i==self.dim-1 and j==0:\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j+1]+=1\n",
    "            elif i==self.dim-1 and j==self.dim-1:\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i][j-1]+=1\n",
    "            elif i==0:\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif i==self.dim-1:\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "            elif j==0:\n",
    "                res[i-1][j]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif j==self.dim-1:\n",
    "                res[i-1][j]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i][j-1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "            else:\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "\n",
    "        return(res)\n",
    "    \n",
    "    #produce dataset\n",
    "    def frames(self, n_frames, loc1, loc2):\n",
    "        frames = np.empty((n_frames, self.dim, self.dim))\n",
    "        for i in range(n_frames):\n",
    "            loc1_tmp = loc1[loc1[:,i].nonzero()[0],i]\n",
    "            loc2_tmp = loc2[loc2[:,i].nonzero()[0],i]\n",
    "            intervals = np.arange(0,1,1/self.dim)\n",
    "            loc1_index = []\n",
    "            loc2_index = []\n",
    "#             print(loc1_tmp.shape)\n",
    "            for n in range(loc1_tmp.shape[0]):\n",
    "#                 print(loc1_tmp)\n",
    "                loc1_index.append(bisect.bisect_left(intervals, loc1_tmp[n])-1)\n",
    "                loc2_index.append(bisect.bisect_left(intervals, loc2_tmp[n])-1)\n",
    "            frames[i][:][:]=self.frame(loc1_index, loc2_index)\n",
    "        return frames\n",
    "\n",
    "# final image generator\n",
    "def final_image(dim, n_frames):\n",
    "    n = np.random.poisson(lam=10, size=1)\n",
    "    loc_mat = np.random.rand(n[0],2)\n",
    "    intervals = np.arange(0,1,1/dim)\n",
    "    loc1 = []\n",
    "    loc2 = []\n",
    "    for n in range(loc_mat.shape[0]):\n",
    "        loc1.append(bisect.bisect_left(intervals, loc_mat[n,0])-1)\n",
    "        loc2.append(bisect.bisect_left(intervals, loc_mat[n,1])-1)\n",
    "    x = np.zeros((dim,dim))\n",
    "    for i,j in zip(loc1,loc2):\n",
    "        x[i][j] += 1\n",
    "    #generate location matrices\n",
    "#     print(loc_mat[:,0].shape)\n",
    "    binom = np.random.binomial(n=1,p=min(1,4/loc_mat.shape[0]),size=(loc_mat.shape[0],n_frames))\n",
    "#     print(binom.shape)\n",
    "    loc1 = np.multiply(np.reshape(loc_mat[:,0],(loc_mat.shape[0],-1)),binom)\n",
    "    loc2 = np.multiply(np.reshape(loc_mat[:,1],(loc_mat.shape[0],-1)),binom)\n",
    "    loc1 = loc1[loc1[:,:].nonzero()[0],:]\n",
    "    loc2 = loc2[loc2[:,:].nonzero()[0],:]\n",
    "    return(x, loc1, loc2)\n",
    "\n",
    "\n",
    "# images generator function\n",
    "def frames_data_fun(n_images, n_frames, dim):\n",
    "    labels = np.zeros((n_images, 2, dim, dim))\n",
    "    data = np.empty((n_images, n_frames, dim, dim))\n",
    "    for n in range(n_images):\n",
    "        x, loc1, loc2 = final_image(dim, n_frames)\n",
    "        tmp = Frame_generator(dim)\n",
    "        frames = tmp.frames(n_frames=n_frames, loc1=loc1, loc2=loc2)\n",
    "        labels[n][1][:][:]=x\n",
    "        m = (x!=0)\n",
    "        labels[n][0][:][:]=1*m\n",
    "        data[n][:][:][:]=frames\n",
    "    return(labels, data)\n",
    "\n",
    "# call images generator function\n",
    "# 1000 images, 10000 frames, 100X100 dimension\n",
    "n_images = 200\n",
    "n_frames = 20\n",
    "dim = 7\n",
    "res = frames_data_fun(n_images=n_images, n_frames=n_frames, dim=dim)\n",
    "labels = res[0]\n",
    "data = res[1]\n",
    "\n",
    "print(data.shape)\n",
    "# print('data frame:', data[2,3,:,:])\n",
    "# print('lable:', labels[2,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "channel_dim = data.shape[1]\n",
    "input_dim=data.shape[2]\n",
    "data_samples = len(data)\n",
    "train_samples = round(0.8*data_samples)\n",
    "conv_layers0 = 16\n",
    "\n",
    "# # Image preprocessing modules\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Pad(4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomCrop(32),\n",
    "# transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 20, 7, 7)\n",
      "(40, 20, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Data loader\n",
    "def datasets_indices(data_samples, train_samples):    \n",
    "    indices = np.arange(data_samples)\n",
    "    #print(indices)\n",
    "    train_indices =  random.sample(list(indices), train_samples)\n",
    "    #print(train_indices)\n",
    "    test_indices = list(set(list(indices))-set(train_indices))\n",
    "    #print(test_indices)\n",
    "    return(train_indices, test_indices)\n",
    "\n",
    "indices = datasets_indices(data_samples, train_samples)\n",
    "train_loader = data[indices[0],:,:,:]\n",
    "train_labels = labels[indices[0],:,:]\n",
    "test_loader = data[indices[1],:,:,:]\n",
    "test_labels = labels[indices[1],:,:]\n",
    "\n",
    "print(train_loader.shape)\n",
    "print(test_loader.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defind the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "(None, 20, 7, 7, 1)\n",
      "conv2D shape (None, 20, 7, 7, 10)\n",
      "(None, 20, 7, 7, 10)\n",
      "conv2D shape (None, 20, 7, 7, 10)\n",
      "(None, 20, 7, 7, 10)\n",
      "reshape (None, 20, 490)\n",
      "LSTM (None, 98)\n",
      "sigmoid (None, 98)\n",
      "reshape2 (None, 2, 7, 7)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not iterable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-77a0e4b66eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m model.compile(loss='binary_crossentropy',\n\u001b[1;32m     75\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m               \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m              )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                            \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                            \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                            **kwargs)\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_updates\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    912\u001b[0m                             metric_result = weighted_metric_fn(y_true, y_pred,\n\u001b[1;32m    913\u001b[0m                                                                \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m                                                                mask=masks[i])\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                         \u001b[0;31m# Append to self.metrics_names, self.metric_tensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \"\"\"\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-77a0e4b66eee>\u001b[0m in \u001b[0;36mcustomloss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mloss_layer0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m#         print(loss_layer0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mloss_layer0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_layer0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mloss_layer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#     for image in range(x.shape[0]):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/jupyterhub/2018-02-19/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0minvoked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \"\"\"\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'Tensor' object is not iterable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not iterable."
     ]
    }
   ],
   "source": [
    "# Convolution\n",
    "kernel_size = 3\n",
    "filters = 10\n",
    "pool_size = 4\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 1\n",
    "\n",
    "# Training\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "####define a model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(n_frames, dim, dim, 1)))\n",
    "print(model.output_shape)\n",
    "model.add(TimeDistributed(Conv2D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                data_format=\"channels_last\",\n",
    "                input_shape=(n_frames, dim, dim, 1))))\n",
    "print('conv2D shape', model.output_shape)\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='same')))\n",
    "print (model.output_shape)\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                data_format=\"channels_last\",\n",
    "                input_shape=(n_frames, dim, dim, 1))))\n",
    "print('conv2D shape', model.output_shape)\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='same')))\n",
    "print (model.output_shape)\n",
    "\n",
    "model.add(Reshape((n_frames,dim*dim*filters)))\n",
    "print('reshape', model.output_shape)\n",
    "model.add(LSTM(2*dim*dim, return_sequences=False, input_shape=(n_frames, dim*dim)))\n",
    "print('LSTM', model.output_shape)\n",
    "model.add(Activation('sigmoid'))\n",
    "print('sigmoid', model.output_shape)\n",
    "model.add(Reshape((2,dim,dim)))\n",
    "print('reshape2', model.output_shape)\n",
    "\n",
    "####\n",
    "\n",
    "####define a loss function\n",
    "\n",
    "def customloss(y_true,y_pred):\n",
    "    loss_layer0 = -(y_true[:,0,:,:]*K.log(y_pred[:,0,:,:])*10+(1-y_true[:,0,:,:])*K.log(1-y_pred[:,0,:,:]))\n",
    "#         print(loss_layer0)\n",
    "    loss_layer0 = sum(loss_layer0)\n",
    "    loss_layer1 = 0\n",
    "#     for image in range(x.shape[0]):\n",
    "#         for i in range(x.shape[2]):\n",
    "#             for j in range(x.shape[3]):\n",
    "#                 if y[image,0,i,j]==1:\n",
    "#                     loss_layer1+=abs(y[image,1,i,j]-x[image,1,i,j])/(x.shape[2]^2)\n",
    "    totloss = loss_layer0+loss_layer1\n",
    "    return totloss\n",
    "    \n",
    "####\n",
    "\n",
    "####compile the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', customloss]\n",
    "             )\n",
    "\n",
    "####\n",
    "\n",
    "print('Train...')\n",
    "print('train_loader.shape', train_loader.shape)\n",
    "print('test shape', test_loader.shape)\n",
    "print('train data shape', train_loader.shape)\n",
    "print('train label shape', train_labels.shape)\n",
    "print('test data shape', test_loader.shape)\n",
    "print('test label shape', test_labels.shape)\n",
    "model.fit(np.expand_dims(train_loader,4), train_labels[:,:,:,:],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs)\n",
    "score, acc = model.evaluate(np.expand_dims(test_loader,4), test_labels[:,:,:,:], batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n",
      "2.1.6\n"
     ]
    }
   ],
   "source": [
    "print(tf.VERSION)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
