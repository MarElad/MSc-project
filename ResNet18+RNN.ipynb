{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 18 modified with generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/eym16/anaconda3/lib/python3.6/site-packages')\n",
    "\n",
    "import numpy as np\n",
    "import bisect\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling2D, Conv2D\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.datasets import imdb\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers import InputLayer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 50, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#frames generator class\n",
    "class Frame_generator(object):\n",
    "\n",
    "    def __init__(self, dim, train_samples=4):\n",
    "#         self.array = array\n",
    "        self.dim = dim\n",
    "        self.train_samples = train_samples\n",
    "        self.zeros = np.zeros((dim, dim))\n",
    "#         self.itemindex = self.itemindex_fun\n",
    "#         self.indices = self.datasets_indices\n",
    "#         self.frame = self.frame(x=array)\n",
    "        \n",
    "#     def itemindex_fun(self,value):\n",
    "#         itemindex = np.where(self.array==value)\n",
    "#         return itemindex\n",
    "    \n",
    "#     def datasets_indices(self, train_samples):\n",
    "#         indices = np.arange(len(self.itemindex(1)[0]))\n",
    "#         one_indices =  random.sample(list(indices), train_samples)\n",
    "#         return(one_indices)\n",
    "\n",
    "    #using self.definitions for the functions didn't work out\n",
    "    #forward part doesn't work\n",
    "    def frame(self, loc1, loc2):\n",
    "        res = np.copy(self.zeros)\n",
    "        for i,j in zip(loc1,loc2):\n",
    "#             print('i:', i)\n",
    "#             print('j:', j)\n",
    "            res[i][j]+=1\n",
    "            if i==0 and j==0:\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif i==0 and j==self.dim-1:\n",
    "                res[i][j-1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "            elif i==self.dim-1 and j==0:\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j+1]+=1\n",
    "            elif i==self.dim-1 and j==self.dim-1:\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i][j-1]+=1\n",
    "            elif i==0:\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif i==self.dim-1:\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "            elif j==0:\n",
    "                res[i-1][j]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif j==self.dim-1:\n",
    "                res[i-1][j]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i][j-1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "            else:\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "\n",
    "        return(res)\n",
    "    \n",
    "    #produce dataset\n",
    "    def frames(self, n_frames, loc1, loc2):\n",
    "        frames = np.empty((n_frames, self.dim, self.dim))\n",
    "        for i in range(n_frames):\n",
    "            loc1_tmp = loc1[loc1[:,i].nonzero()[0],i]\n",
    "            loc2_tmp = loc2[loc2[:,i].nonzero()[0],i]\n",
    "            intervals = np.arange(0,1,1/self.dim)\n",
    "            loc1_index = []\n",
    "            loc2_index = []\n",
    "#             print(loc1_tmp.shape)\n",
    "            for n in range(loc1_tmp.shape[0]):\n",
    "#                 print(loc1_tmp)\n",
    "                loc1_index.append(bisect.bisect_left(intervals, loc1_tmp[n])-1)\n",
    "                loc2_index.append(bisect.bisect_left(intervals, loc2_tmp[n])-1)\n",
    "            frames[i][:][:]=self.frame(loc1_index, loc2_index)\n",
    "        return frames\n",
    "\n",
    "# final image generator\n",
    "def final_image(dim, n_frames):\n",
    "    n = np.random.poisson(lam=10, size=1)\n",
    "    loc_mat = np.random.rand(n[0],2)\n",
    "    intervals = np.arange(0,1,1/dim)\n",
    "    loc1 = []\n",
    "    loc2 = []\n",
    "    for n in range(loc_mat.shape[0]):\n",
    "        loc1.append(bisect.bisect_left(intervals, loc_mat[n,0])-1)\n",
    "        loc2.append(bisect.bisect_left(intervals, loc_mat[n,1])-1)\n",
    "    x = np.zeros((dim,dim))\n",
    "    for i,j in zip(loc1,loc2):\n",
    "        x[i][j] += 1\n",
    "    #generate location matrices\n",
    "#     print(loc_mat[:,0].shape)\n",
    "    binom = np.random.binomial(n=1,p=min(1,4/loc_mat.shape[0]),size=(loc_mat.shape[0],n_frames))\n",
    "#     print(binom.shape)\n",
    "    loc1 = np.multiply(np.reshape(loc_mat[:,0],(loc_mat.shape[0],-1)),binom)\n",
    "    loc2 = np.multiply(np.reshape(loc_mat[:,1],(loc_mat.shape[0],-1)),binom)\n",
    "    loc1 = loc1[loc1[:,:].nonzero()[0],:]\n",
    "    loc2 = loc2[loc2[:,:].nonzero()[0],:]\n",
    "    return(x, loc1, loc2)\n",
    "\n",
    "\n",
    "# images generator function\n",
    "def frames_data_fun(n_images, n_frames, dim):\n",
    "    labels = np.zeros((n_images, 2, dim, dim))\n",
    "    data = np.empty((n_images, n_frames, dim, dim))\n",
    "    for n in range(n_images):\n",
    "        x, loc1, loc2 = final_image(dim, n_frames)\n",
    "        tmp = Frame_generator(dim)\n",
    "        frames = tmp.frames(n_frames=n_frames, loc1=loc1, loc2=loc2)\n",
    "        labels[n][1][:][:]=x\n",
    "        m = (x!=0)\n",
    "        labels[n][0][:][:]=1*m\n",
    "        data[n][:][:][:]=frames\n",
    "    return(labels, data)\n",
    "\n",
    "# call images generator function\n",
    "# 1000 images, 10000 frames, 100X100 dimension\n",
    "n_images = 88\n",
    "n_frames = 50\n",
    "dim = 10\n",
    "res = frames_data_fun(n_images=n_images, n_frames=n_frames, dim=dim)\n",
    "labels = res[0]\n",
    "data = res[1]\n",
    "\n",
    "print(data.shape)\n",
    "# print('data frame:', data[2,3,:,:])\n",
    "# print('lable:', labels[2,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 50, 10, 10)\n",
      "(18, 50, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data_samples = len(data)\n",
    "train_samples = round(0.8*data_samples)\n",
    "\n",
    "# Data loader\n",
    "def datasets_indices(data_samples, train_samples):    \n",
    "    indices = np.arange(data_samples)\n",
    "    #print(indices)\n",
    "    train_indices =  random.sample(list(indices), train_samples)\n",
    "    #print(train_indices)\n",
    "    test_indices = list(set(list(indices))-set(train_indices))\n",
    "    #print(test_indices)\n",
    "    return(train_indices, test_indices)\n",
    "\n",
    "indices = datasets_indices(data_samples, train_samples)\n",
    "train_loader = data[indices[0],:,:,:]\n",
    "train_labels = labels[indices[0],:,:]\n",
    "test_loader = data[indices[1],:,:,:]\n",
    "test_labels = labels[indices[1],:,:]\n",
    "\n",
    "print(train_loader.shape)\n",
    "print(test_loader.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defind the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "(None, 50, 10, 10, 1)\n",
      "conv2D shape (None, 50, 10, 10, 20)\n",
      "(None, 50, 10, 10, 20)\n",
      "conv2D shape (None, 50, 10, 10, 20)\n",
      "(None, 50, 10, 10, 20)\n",
      "conv2D shape (None, 50, 10, 10, 20)\n",
      "(None, 50, 10, 10, 20)\n",
      "reshape (None, 50, 2000)\n",
      "LSTM (None, 200)\n",
      "sigmoid (None, 200)\n",
      "reshape2 (None, 2, 10, 10)\n",
      "y_pred shape (?, 2, 10, 10)\n",
      "Train...\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 180s 3s/step - loss: 3965.2917 - accuracy_met: 1896.4000\n",
      "Epoch 2/5\n"
     ]
    }
   ],
   "source": [
    "# Convolution\n",
    "kernel_size = 3\n",
    "filters = 20\n",
    "pool_size = 4\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 1\n",
    "\n",
    "# Training\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "####define a model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(n_frames, dim, dim, 1)))\n",
    "print(model.output_shape)\n",
    "model.add(TimeDistributed(\n",
    "    Conv2D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                data_format=\"channels_last\",\n",
    "                input_shape=(n_frames, dim, dim, 1))))\n",
    "print('conv2D shape', model.output_shape)\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='same')))\n",
    "print (model.output_shape)\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                data_format=\"channels_last\",\n",
    "                input_shape=(n_frames, dim, dim, 1))))\n",
    "print('conv2D shape', model.output_shape)\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='same')))\n",
    "print (model.output_shape)\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                data_format=\"channels_last\",\n",
    "                input_shape=(n_frames, dim, dim, 1))))\n",
    "print('conv2D shape', model.output_shape)\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='same')))\n",
    "print (model.output_shape)\n",
    "\n",
    "model.add(Reshape((n_frames,dim*dim*filters)))\n",
    "print('reshape', model.output_shape)\n",
    "model.add(LSTM(2*dim*dim, return_sequences=False, input_shape=(n_frames, dim*dim)))\n",
    "print('LSTM', model.output_shape)\n",
    "model.add(Activation('sigmoid'))\n",
    "print('sigmoid', model.output_shape)\n",
    "model.add(Reshape((2,dim,dim)))\n",
    "print('reshape2', model.output_shape)\n",
    "\n",
    "####\n",
    "\n",
    "####define a loss function\n",
    "\n",
    "def customloss(y_true, y_pred):\n",
    "    loss_layer0 = -(y_true[:,0,:,:]*K.log(y_pred[:,0,:,:])*10+(1-y_true[:,0,:,:])*K.log(1-y_pred[:,0,:,:]))\n",
    "#         print(loss_layer0)\n",
    "    loss_layer0 = K.sum(loss_layer0)\n",
    "    loss_layer1 = 0\n",
    "    print('y_pred shape', y_pred.shape)\n",
    "    loss_layer1 = K.abs(y_true[:,1,:,:]-y_pred[:,1,:,:])/K.cast(K.pow(y_pred.shape[2],2), 'float32')*(y_true[:,0,:,:]==1)\n",
    "    totloss = loss_layer0+loss_layer1\n",
    "    return totloss\n",
    "    \n",
    "####\n",
    "def accuracy_met(y_true, y_pred):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    input_dim = y_pred.shape[2]\n",
    "    total = input_dim*input_dim\n",
    "#     print('total', total)\n",
    "    m = (y_true[:,0,:,:]>0)&K.equal(K.round(y_pred[:,0,:,:]),y_true[:,0,:,:])\n",
    "    correct = tf.count_nonzero(K.equal(K.round(y_pred[:,0,:,:]), y_true[:,0,:,:]))-tf.count_nonzero(m&(K.not_equal(K.round(y_pred[:,1,:,:]), y_true[:,1,:,:])))\n",
    "#     print('correct', correct)\n",
    "    return correct/total*100\n",
    "\n",
    "####compile the model\n",
    "\n",
    "####\n",
    "def count_met(y_true, y_pred):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    input_dim = y_pred.shape[2]\n",
    "    total = input_dim*input_dim\n",
    "#     print('total', total)\n",
    "    m = (y_true[:,0,:,:]>0)&K.equal(K.round(y_pred[:,0,:,:]), y_true[:,0,:,:])\n",
    "    correct = tf.count_nonzero(m&(K.equal(K.round(y_pred[:,1,:,:]), y_true[:,1,:,:])))\n",
    "#     print('correct', correct)\n",
    "    return correct\n",
    "\n",
    "####compile the model\n",
    "\n",
    "model.compile(loss=customloss,\n",
    "              optimizer='adam',\n",
    "              metrics=[accuracy_met]\n",
    "             )\n",
    "\n",
    "####\n",
    "def accuracy_met(y_true, y_pred):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    input_dim = y_pred.shape[2]\n",
    "    total = y_true.shape[0]*input_dim*input_dim\n",
    "#     print('total', total)\n",
    "    m = (y_true[:,0,:,:]>0)&K.equal(K.round(y_pred[:,0,:,:]),y_true[:,0,:,:])\n",
    "    correct = tf.count_nonzero(K.equal(K.round(y_pred[:,0,:,:]), y_true[:,0,:,:]))-tf.count_nonzero(m&(K.not_equal(K.round(y_pred[:,1,:,:]), y_true[:,1,:,:])))\n",
    "#     print('correct', correct)\n",
    "    return correct/total*100\n",
    "\n",
    "####\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Train...')\n",
    "\n",
    "    model.fit(np.expand_dims(train_loader,4), train_labels[:,:,:,:],\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs)\n",
    "\n",
    "    ## train accuracy\n",
    "    print('#########')\n",
    "    print('train results')\n",
    "    train_pred = model.predict(np.expand_dims(train_loader,4))\n",
    "    predicted = train_pred.round()\n",
    "    labels = train_labels\n",
    "    print('labels shape', labels.shape)\n",
    "    total = labels.shape[0]*labels.shape[2]*labels.shape[3]\n",
    "    m = (labels[:,0,:,:]>0)*(predicted[:,0,:,:] == labels[:,0,:,:])\n",
    "    correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()-(m*(predicted[:,1,:,:] != labels[:,1,:,:])).sum().item()\n",
    "    semi_correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()\n",
    "    total_ones =  (labels[:,0,:,:]==1).sum().item()\n",
    "    total_zeros = (labels[:,0,:,:]==0).sum().item()\n",
    "    correct_ones = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==1)).sum().item()\n",
    "    correct_zeros = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==0)).sum().item()\n",
    "    print(correct_ones, total_ones, correct_zeros, total_zeros)\n",
    "    print('accuracy:', correct/total*100, '%')\n",
    "    print('semi_correct:', semi_correct/total*100, '%')\n",
    "    print('correct ones:', correct_ones/total_ones*100, '%')\n",
    "    print('correct zeros:', correct_zeros/total_zeros*100, '%')\n",
    "    \n",
    "## test accuracy\n",
    "    print('#########')\n",
    "    print('test results')\n",
    "    test_pred = model.predict(np.expand_dims(test_loader,4))\n",
    "    predicted = test_pred.round()\n",
    "    labels = test_labels\n",
    "    total = labels.shape[0]*labels.shape[2]*labels.shape[3]\n",
    "    print('label shape', labels.shape)\n",
    "    print('total', total)\n",
    "    m = (labels[:,0,:,:]>0)*(predicted[:,0,:,:] == labels[:,0,:,:])\n",
    "    correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()-(m*(predicted[:,1,:,:] != labels[:,1,:,:])).sum().item()\n",
    "    semi_correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()\n",
    "    print('correct', correct)\n",
    "    print('semi correct', semi_correct)\n",
    "    total_ones =  (labels[:,0,:,:]==1).sum().item()\n",
    "    total_zeros = (labels[:,0,:,:]==0).sum().item()\n",
    "    correct_ones = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==1)).sum().item()\n",
    "    correct_zeros = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==0)).sum().item()\n",
    "    print(correct_ones, total_ones, correct_zeros, total_zeros)\n",
    "    print('accuracy:', correct/total*100, '%')\n",
    "    print('semi_correct:', semi_correct/total*100, '%')\n",
    "    print('correct ones:', correct_ones/total_ones*100, '%')\n",
    "    print('correct zeros:', correct_zeros/total_zeros*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
