{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/eym16/anaconda3/lib/python3.6/site-packages')\n",
    "\n",
    "import numpy as np\n",
    "import bisect\n",
    "\n",
    "import keras.backend as K\n",
    "import keras.layers\n",
    "from keras.layers import LSTM\n",
    "import keras.models\n",
    "import keras.regularizers\n",
    "\n",
    "import keras_resnet.blocks\n",
    "import keras_resnet.layers\n",
    "import keras_resnet.models\n",
    "\n",
    "import numpy as np\n",
    "import bisect\n",
    "\n",
    "keras.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 155, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#frames generator class\n",
    "class Frame_generator(object):\n",
    "\n",
    "    def __init__(self, dim, train_samples=4):\n",
    "#         self.array = array\n",
    "        self.dim = dim\n",
    "        self.train_samples = train_samples\n",
    "        self.zeros = np.zeros((dim, dim))\n",
    "#         self.itemindex = self.itemindex_fun\n",
    "#         self.indices = self.datasets_indices\n",
    "#         self.frame = self.frame(x=array)\n",
    "        \n",
    "#     def itemindex_fun(self,value):\n",
    "#         itemindex = np.where(self.array==value)\n",
    "#         return itemindex\n",
    "    \n",
    "#     def datasets_indices(self, train_samples):\n",
    "#         indices = np.arange(len(self.itemindex(1)[0]))\n",
    "#         one_indices =  random.sample(list(indices), train_samples)\n",
    "#         return(one_indices)\n",
    "\n",
    "    #using self.definitions for the functions didn't work out\n",
    "    #forward part doesn't work\n",
    "    def frame(self, loc1, loc2):\n",
    "        res = np.copy(self.zeros)\n",
    "        for i,j in zip(loc1,loc2):\n",
    "#             print('i:', i)\n",
    "#             print('j:', j)\n",
    "            res[i][j]+=1\n",
    "            if i==0 and j==0:\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif i==0 and j==self.dim-1:\n",
    "                res[i][j-1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "            elif i==self.dim-1 and j==0:\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j+1]+=1\n",
    "            elif i==self.dim-1 and j==self.dim-1:\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i][j-1]+=1\n",
    "            elif i==0:\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif i==self.dim-1:\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "            elif j==0:\n",
    "                res[i-1][j]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "            elif j==self.dim-1:\n",
    "                res[i-1][j]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i][j-1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "            else:\n",
    "                res[i-1][j-1]+=1\n",
    "                res[i-1][j]+=1\n",
    "                res[i-1][j+1]+=1\n",
    "                res[i][j-1]+=1\n",
    "                res[i][j+1]+=1\n",
    "                res[i+1][j-1]+=1\n",
    "                res[i+1][j]+=1\n",
    "                res[i+1][j+1]+=1\n",
    "\n",
    "        return(res)\n",
    "    \n",
    "    #produce dataset\n",
    "    def frames(self, n_frames, loc1, loc2):\n",
    "        frames = np.empty((n_frames, self.dim, self.dim))\n",
    "        for i in range(n_frames):\n",
    "            loc1_tmp = loc1[loc1[:,i].nonzero()[0],i]\n",
    "            loc2_tmp = loc2[loc2[:,i].nonzero()[0],i]\n",
    "            intervals = np.arange(0,1,1/self.dim)\n",
    "            loc1_index = []\n",
    "            loc2_index = []\n",
    "#             print(loc1_tmp.shape)\n",
    "            for n in range(loc1_tmp.shape[0]):\n",
    "#                 print(loc1_tmp)\n",
    "                loc1_index.append(bisect.bisect_left(intervals, loc1_tmp[n])-1)\n",
    "                loc2_index.append(bisect.bisect_left(intervals, loc2_tmp[n])-1)\n",
    "            frames[i][:][:]=self.frame(loc1_index, loc2_index)\n",
    "        return frames\n",
    "\n",
    "# final image generator\n",
    "def final_image(dim, n_frames):\n",
    "    n = np.random.poisson(lam=10, size=1)\n",
    "    loc_mat = np.random.rand(n[0],2)\n",
    "    intervals = np.arange(0,1,1/dim)\n",
    "    loc1 = []\n",
    "    loc2 = []\n",
    "    for n in range(loc_mat.shape[0]):\n",
    "        loc1.append(bisect.bisect_left(intervals, loc_mat[n,0])-1)\n",
    "        loc2.append(bisect.bisect_left(intervals, loc_mat[n,1])-1)\n",
    "    x = np.zeros((dim,dim))\n",
    "    for i,j in zip(loc1,loc2):\n",
    "        x[i][j] += 1\n",
    "    #generate location matrices\n",
    "#     print(loc_mat[:,0].shape)\n",
    "    binom = np.random.binomial(n=1,p=min(1,4/loc_mat.shape[0]),size=(loc_mat.shape[0],n_frames))\n",
    "#     print(binom.shape)\n",
    "    loc1 = np.multiply(np.reshape(loc_mat[:,0],(loc_mat.shape[0],-1)),binom)\n",
    "    loc2 = np.multiply(np.reshape(loc_mat[:,1],(loc_mat.shape[0],-1)),binom)\n",
    "    loc1 = loc1[loc1[:,:].nonzero()[0],:]\n",
    "    loc2 = loc2[loc2[:,:].nonzero()[0],:]\n",
    "    return(x, loc1, loc2)\n",
    "\n",
    "\n",
    "# images generator function\n",
    "def frames_data_fun(n_images, n_frames, dim):\n",
    "    labels = np.zeros((n_images, 2, dim, dim))\n",
    "    data = np.empty((n_images, n_frames, dim, dim))\n",
    "    for n in range(n_images):\n",
    "        x, loc1, loc2 = final_image(dim, n_frames)\n",
    "        tmp = Frame_generator(dim)\n",
    "        frames = tmp.frames(n_frames=n_frames, loc1=loc1, loc2=loc2)\n",
    "        labels[n][1][:][:]=x\n",
    "        m = (x!=0)\n",
    "        labels[n][0][:][:]=1*m\n",
    "        data[n][:][:][:]=frames\n",
    "    return(labels, data)\n",
    "\n",
    "# call images generator function\n",
    "# 1000 images, 10000 frames, 100X100 dimension\n",
    "n_images = 400\n",
    "n_frames = 155\n",
    "dim = 10\n",
    "res = frames_data_fun(n_images=n_images, n_frames=n_frames, dim=dim)\n",
    "labels = res[0]\n",
    "data = res[1]\n",
    "\n",
    "print(data.shape)\n",
    "# print('data frame:', data[2,3,:,:])\n",
    "# print('lable:', labels[2,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 155, 10, 10)\n",
      "(80, 155, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data_samples = len(data)\n",
    "train_samples = round(0.8*data_samples)\n",
    "\n",
    "# Data loader\n",
    "def datasets_indices(data_samples, train_samples):    \n",
    "    indices = np.arange(data_samples)\n",
    "    #print(indices)\n",
    "    train_indices =  random.sample(list(indices), train_samples)\n",
    "    #print(train_indices)\n",
    "    test_indices = list(set(list(indices))-set(train_indices))\n",
    "    #print(test_indices)\n",
    "    return(train_indices, test_indices)\n",
    "\n",
    "indices = datasets_indices(data_samples, train_samples)\n",
    "train_loader = data[indices[0],:,:,:]\n",
    "train_labels = labels[indices[0],:,:]\n",
    "test_loader = data[indices[1],:,:,:]\n",
    "test_labels = labels[indices[1],:,:]\n",
    "\n",
    "print(train_loader.shape)\n",
    "print(test_loader.shape)\n",
    "\n",
    "input_dim = train_loader.shape[2]\n",
    "n_frames = train_loader.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp shape (?, 155, 10, 10)\n",
      "(?, 32, 10, 10)\n",
      "bn1 (?, 16, 10, 10)\n",
      "ac1 (?, 16, 10, 10)\n",
      "conv1 (?, 32, 10, 10)\n",
      "bn2 (?, 32, 10, 10)\n",
      "ac2 (?, 32, 10, 10)\n",
      "conv2 (?, 32, 10, 10)\n",
      "skip shape (?, 32, 10, 10)\n",
      "conv shape (?, 32, 10, 10)\n",
      "prev shape (?, 16, 10, 10)\n",
      "Residual block mapping 16 channels to 32 channels built\n",
      "(?, 64, 10, 10)\n",
      "bn1 (?, 32, 10, 10)\n",
      "ac1 (?, 32, 10, 10)\n",
      "conv1 (?, 64, 10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/2018-02-19/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/eym16/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn2 (?, 64, 10, 10)\n",
      "ac2 (?, 64, 10, 10)\n",
      "conv2 (?, 64, 10, 10)\n",
      "skip shape (?, 64, 10, 10)\n",
      "conv shape (?, 64, 10, 10)\n",
      "prev shape (?, 32, 10, 10)\n",
      "Residual block mapping 32 channels to 64 channels built\n",
      "(?, 1240, 10, 10)\n",
      "bn1 (?, 64, 10, 10)\n",
      "ac1 (?, 64, 10, 10)\n",
      "conv1 (?, 1240, 10, 10)\n",
      "bn2 (?, 1240, 10, 10)\n",
      "ac2 (?, 1240, 10, 10)\n",
      "conv2 (?, 1240, 10, 10)\n",
      "skip shape (?, 1240, 10, 10)\n",
      "conv shape (?, 1240, 10, 10)\n",
      "prev shape (?, 64, 10, 10)\n",
      "Residual block mapping 64 channels to 1240 channels built\n",
      "r3 shape (?, 1240, 10, 10)\n",
      "r8 shape (?, 2, 10, 10)\n",
      "y_pred Tensor(\"loss_3/reshape_8_loss/strided_slice:0\", shape=(?, 2, 10), dtype=float32)\n",
      "Tensor(\"loss_3/reshape_8_loss/Neg:0\", shape=(?, 10, 10), dtype=float32)\n",
      "y_pred shape (?, 2, 10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/2018-02-19/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:84: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"re...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "train shape: (320, 155, 10, 10, 1)\n",
      "lables shape (320, 2, 10, 10)\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 8372.4013\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 33s 103ms/step - loss: 8163.2271\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 32s 101ms/step - loss: 8092.5561\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 33s 103ms/step - loss: 8000.0130\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 35s 111ms/step - loss: 7922.4064\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 34s 107ms/step - loss: 7851.4793\n",
      "Epoch 7/100\n",
      " 64/320 [=====>........................] - ETA: 28s - loss: 7711.4849"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam\n",
    "from keras.layers import BatchNormalization, Convolution2D, Input, merge\n",
    "from keras.layers.core import Activation, Layer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pydot\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    "Keras Customizable Residual Unit\n",
    "This is a simplified implementation of the basic (no bottlenecks) full pre-activation residual unit from He, K., Zhang, X., Ren, S., Sun, J., \"Identity Mappings in Deep Residual Networks\" (http://arxiv.org/abs/1603.05027v2).\n",
    "'''\n",
    "#hyper parameters\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def conv_block(feat_maps_out, prev):\n",
    "    prev = keras.layers.BatchNormalization(axis=1)(prev) # Specifying the axis and mode allows for later merging\n",
    "    print('bn1', prev.shape)\n",
    "    prev = keras.layers.Activation('relu')(prev)\n",
    "    print('ac1', prev.shape)\n",
    "    prev = keras.layers.Convolution2D(feat_maps_out, kernel_size=3, strides=1, padding='same')(prev)\n",
    "    print('conv1', prev.shape)\n",
    "    prev = keras.layers.BatchNormalization(axis=1)(prev) # Specifying the axis and mode allows for later merging\n",
    "    print('bn2', prev.shape)\n",
    "    prev = keras.layers.Activation('relu')(prev)\n",
    "    print('ac2', prev.shape)\n",
    "    prev = keras.layers.Convolution2D(feat_maps_out, 3, strides=1, padding='same')(prev)\n",
    "    print('conv2', prev.shape)\n",
    "    return prev\n",
    "\n",
    "\n",
    "def skip_block(feat_maps_in, feat_maps_out, prev):\n",
    "    if feat_maps_in != feat_maps_out:\n",
    "        # This adds in a 1x1 convolution on shortcuts that map between an uneven amount of channels\n",
    "        prev = keras.layers.Convolution2D(feat_maps_out, 1, strides=1, padding='same')(prev)\n",
    "        print(prev.shape)\n",
    "    return prev \n",
    "\n",
    "\n",
    "def Residual(feat_maps_in, feat_maps_out, prev_layer):\n",
    "    '''\n",
    "    A customizable residual unit with convolutional and shortcut blocks\n",
    "    Args:\n",
    "      feat_maps_in: number of channels/filters coming in, from input or previous layer\n",
    "      feat_maps_out: how many output channels/filters this block will produce\n",
    "      prev_layer: the previous layer\n",
    "    '''\n",
    "\n",
    "    skip = skip_block(feat_maps_in, feat_maps_out, prev_layer)\n",
    "    conv = conv_block(feat_maps_out, prev_layer)\n",
    "    \n",
    "    print('skip shape', skip.shape)\n",
    "    print('conv shape', conv.shape)\n",
    "    print('prev shape', prev_layer.shape)\n",
    "\n",
    "    print('Residual block mapping '+str(feat_maps_in)+' channels to '+str(feat_maps_out)+' channels built')\n",
    "    return merge([skip, conv], mode='sum') # the residual connection\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # NOTE: Toy example shows structure\n",
    "    img_rows = dim  \n",
    "    img_cols = dim \n",
    "\n",
    "    inp = Input((n_frames, img_rows, img_cols))\n",
    "    print('inp shape', inp.shape)\n",
    "    cnv1 = keras.layers.Convolution2D(16, kernel_size=3, strides=1, activation='relu', input_shape=(n_frames, img_rows, img_cols, 1), padding='same')(inp)\n",
    "    r1 = Residual(16, 32, cnv1)\n",
    "    # An example residual unit coming after a convolutional layer. NOTE: the above residual takes the 64 output channels\n",
    "    # from the Convolutional2D layer as the first argument to the Residual function\n",
    "    r2 = Residual(32, 64, r1)\n",
    "    r3 = Residual(64, n_frames*8, r2)\n",
    "    print('r3 shape', r3.shape)\n",
    "#     r4 = keras.layers.Reshape((dim,dim,int(r3.shape[1])*int(r3.shape[4])))(r3)\n",
    "#     print('r4 shape', r4.shape)\n",
    "    r5 = keras.layers.Reshape((n_frames,dim*dim*8))(r3)\n",
    "    r6 = keras.layers.LSTM(2*dim*dim, return_sequences=False, input_shape=(n_frames, dim*dim))(r5)\n",
    "    r7 = Activation('sigmoid')(r6)\n",
    "    r8 = keras.layers.Reshape((2,dim,dim))(r7)\n",
    "    print('r8 shape', r8.shape)\n",
    "\n",
    "    model = Model(input=inp, output=r8)\n",
    "#     model.compile(optimizer=Nadam(lr=1e-5), loss='mean_squared_error')\n",
    "\n",
    "#     plot_model(model, to_file='./toy_model.png', show_shapes=True)\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "####define a loss function\n",
    "\n",
    "def customloss(y_true, y_pred):\n",
    "    print('y_pred', y_pred[:,:,:,0])\n",
    "    loss_layer0 = -(y_true[:,0,:,:]*K.log(keras.backend.clip(y_pred[:,0,:,:], 0.001,0.999))*10+(1-y_true[:,0,:,:])*K.log(1-keras.backend.clip(y_pred[:,0,:,:], 0.001, 0.999)))\n",
    "    print(loss_layer0)\n",
    "    loss_layer0 = K.sum(loss_layer0)\n",
    "    loss_layer1 = 0\n",
    "    print('y_pred shape', y_pred.shape)\n",
    "    loss_layer1 = K.abs(y_true[:,1,:,:]-y_pred[:,1,:,:])/K.cast(K.pow(y_pred.shape[2],2), 'float32')*(y_true[:,0,:,:]==1)\n",
    "    totloss = loss_layer0+loss_layer1\n",
    "    return totloss\n",
    "    \n",
    "####\n",
    "\n",
    "####compile the model\n",
    "\n",
    "model.compile(loss=customloss,\n",
    "              optimizer='adam'\n",
    "             )\n",
    "\n",
    "####\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Train...')\n",
    "    \n",
    "    print('train shape:', (np.expand_dims(train_loader,4)).shape)\n",
    "    print('lables shape', train_labels.shape)\n",
    "    \n",
    "    model.fit(train_loader, train_labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs)\n",
    "\n",
    "    ## train accuracy\n",
    "    print('#########')\n",
    "    print('train results')\n",
    "    train_pred = model.predict(train_loader)\n",
    "    predicted = train_pred.round()\n",
    "    labels = train_labels\n",
    "    print('labels shape', labels.shape)\n",
    "    total = labels.shape[0]*labels.shape[2]*labels.shape[3]\n",
    "    m = (labels[:,0,:,:]>0)*(predicted[:,0,:,:] == labels[:,0,:,:])\n",
    "    print('predicted', predicted[:,:,:,:].shape)\n",
    "    print('labels', labels[:,:,:,:].shape)\n",
    "    correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()-(m*(predicted[:,1,:,:] != labels[:,1,:,:])).sum().item()\n",
    "    semi_correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()\n",
    "    total_ones =  (labels[:,0,:,:]==1).sum().item()\n",
    "    total_zeros = (labels[:,0,:,:]==0).sum().item()\n",
    "    correct_ones = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==1)).sum().item()\n",
    "    correct_zeros = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==0)).sum().item()\n",
    "    print(correct_ones, total_ones, correct_zeros, total_zeros)\n",
    "    print('accuracy:', correct/total*100, '%')\n",
    "    print('semi_correct:', semi_correct/total*100, '%')\n",
    "    print('correct ones:', correct_ones/total_ones*100, '%')\n",
    "    print('correct zeros:', correct_zeros/total_zeros*100, '%')\n",
    "    \n",
    "## test accuracy\n",
    "    print('#########')\n",
    "    print('test results')\n",
    "    test_pred = model.predict(test_loader)\n",
    "    predicted = test_pred.round()\n",
    "    labels = test_labels\n",
    "    total = labels.shape[0]*labels.shape[2]*labels.shape[3]\n",
    "    print('label shape', labels.shape)\n",
    "    print('total', total)\n",
    "    m = (labels[:,0,:,:]>0)*(predicted[:,0,:,:] == labels[:,0,:,:])\n",
    "    correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()-(m*(predicted[:,1,:,:] != labels[:,1,:,:])).sum().item()\n",
    "    semi_correct = (predicted[:,0,:,:] == labels[:,0,:,:]).sum().item()\n",
    "    print('correct', correct)\n",
    "    print('semi correct', semi_correct)\n",
    "    total_ones =  (labels[:,0,:,:]==1).sum().item()\n",
    "    total_zeros = (labels[:,0,:,:]==0).sum().item()\n",
    "    correct_ones = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==1)).sum().item()\n",
    "    correct_zeros = ((predicted[:,0,:,:] == labels[:,0,:,:])*(labels[:,0,:,:]==0)).sum().item()\n",
    "    print(correct_ones, total_ones, correct_zeros, total_zeros)\n",
    "    print('accuracy:', correct/total*100, '%')\n",
    "    print('semi_correct:', semi_correct/total*100, '%')\n",
    "    print('correct ones:', correct_ones/total_ones*100, '%')\n",
    "    print('correct zeros:', correct_zeros/total_zeros*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([1, 3])\n",
    "print((a==b).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
